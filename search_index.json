[["index.html", "In the Future 1 Shervin Kaandorps Portfolio 1.1 Preface", " In the Future Shervin Kaandorp 20-6-2021 1 Shervin Kaandorps Portfolio Hello! Welcome to my portfolio. In this portfolio I will showcase my knowledge of working with R. Now, this consists of only portolio assignments (which I will clarify in the preface) but Im planning to add more to send this portfolio to future employers. 1.1 Preface This bookdown is made for the Workflows course of the Data Sciences for Biology minor. In this bookdown, multiple portfolio assignments can be found. The following concepts and technologies were fundamental in this course (retrieved from the Workflows course reader): Open Science File management and formatting following the Guerrilla Analytics Principles Version control and Project management, using Github.com Literate Programming using R flavored Markdown (R Markdown) Relational databases to improve data provenance, computational speed and traceability of observations "],["visualizing-data-from-excel.html", "2 Visualizing data from Excel", " 2 Visualizing data from Excel The data I am using is CE.LIQ.FLOW.062_Tidydata.xlsx which is an experiment where C.elegans nematodes were incubated in different compounds with different concentrations. This dataset was provided by J. Louter which is a researcher for the Lectoraat of the Institute for Life Sciences. Some variables are key to the visualization: the RawData, which is the number of offspring of the C. elegans, the compName, which is the compound in which the C. elegans was incubated and the compConcentration, which is the concentration in which the C. elegans was incubated. Here, ill visualize the data to a graph with ggplot2. There are some values missing in the RawData column in row 192-196. RawData, compName, compConcentration and the expType column all have a General format in Excel. While it is expected that they have a text format. Cell P260 has a comma instead of a dot. The here and readxl packages have been used to import the excel file from the working directory. CE.LIQ.FLOW.062_Tidydata &lt;- read_excel(here(&quot;rawdata/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;)) The variables are inspected with the str() command. as_tibble(CE.LIQ.FLOW.062_Tidydata) %&gt;% select(&quot;RawData&quot;,&quot;compName&quot;,&quot;compConcentration&quot;) %&gt;% str() ## tibble[,3] [360 x 3] (S3: tbl_df/tbl/data.frame) ## $ RawData : num [1:360] 44 37 45 47 41 35 41 36 40 38 ... ## $ compName : chr [1:360] &quot;2,6-diisopropylnaphthalene&quot; &quot;2,6-diisopropylnaphthalene&quot; &quot;2,6-diisopropylnaphthalene&quot; &quot;2,6-diisopropylnaphthalene&quot; ... ## $ compConcentration: chr [1:360] &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; &quot;4.99&quot; ... The data of the RawData and compName columns have been assinged correctly. Nonetheless, the data type for compConcentration has been assinged incorrectly. This should have been numeric instead of character. The data has been visualized using the code here. CE.LIQ.FLOW.062_Tidydata$compConcentration &lt;- gsub(&quot;,&quot;, &quot;.&quot;, CE.LIQ.FLOW.062_Tidydata$compConcentration) # Resolving issue comma in cell P260. CE.LIQ.FLOW.062_Tidydata$compConcentration &lt;- as.numeric(CE.LIQ.FLOW.062_Tidydata$compConcentration, na.rm=TRUE) # Change type of compConcentration to numeric ggplotCLF.062 &lt;- CE.LIQ.FLOW.062_Tidydata %&gt;% ggplot(aes(x=compConcentration,y=RawData,shape=expType,colour=compName)) + geom_point() + labs(x= &quot;Compound Concentration (nM)&quot;, y= &quot;Number of offspring&quot;, title= &quot;Number of offsprings of C.elegans after incubating in a compound&quot;, caption= &quot;the dataset CE.LIQ.FLOW.062_Tidydata has been used&quot;, shape=&quot;Experiment Type&quot;, colour=&quot;Compound&quot;) # Creating graph ggplotCLF.062 Without using the as.numeric function, the x-axis would not be ordered correctly. Because the values are very close to each other, a log10 transformation of the x-axis and a jitter was added. ggplotCLF.062 + scale_x_continuous(trans = &quot;log10&quot;) + geom_jitter(width=0.15) + labs(caption=&quot;the dataset CE.LIQ.FLOW.062_Tidydata has been used and a jitter of 0.15 has been added.&quot;) The positive control for this experiment is Ethanol and the negative control for this experiment is S-medium. To analyze the data, these steps should be performed: The mean offspring of each concentration of each compound should be calculated. The mean offspring of each concentration of each compound should be normalized with the mean offspring of the negative control. Now, a IC50 curve can be made depicting the concentration of the compound on the x-axis and the relative offspring on the y-axis. Additional significance tests are performed to examine a possible significant difference. The data will be normalized for the negative control (controlNegative) and a graph with the normalized data is made with the ggplot2 package (comes with tidyverse): CE.LIQ.FLOW.062_means &lt;- CE.LIQ.FLOW.062_Tidydata %&gt;% group_by(compName,compConcentration, expType) %&gt;% summarize(mean=mean(RawData, na.rm=TRUE)) # Calculating mean S_medium_neg &lt;- CE.LIQ.FLOW.062_means %&gt;% filter(compName==&quot;S-medium&quot;) negative_cont &lt;- S_medium_neg[4] # Retrieving negative control mean CE.LIQ.FLOW.062_means &lt;- CE.LIQ.FLOW.062_means %&gt;% mutate(relative_offspring=mean/negative_cont*100) # Adding relative offspring count CE.LIQ.FLOW.062_means %&gt;% ggplot(aes(x=compConcentration,y=relative_offspring$mean,shape=expType,colour=compName)) + geom_point() + labs(x= &quot;Compound Concentration (nM)&quot;, y= &quot;Relative number of offspring (%)&quot;, title= &quot;Relative C.elegans offspring after incubating in a compound&quot;, caption= &quot;the dataset CE.LIQ.FLOW.062_Tidydata has been used, and the offspring count have been normalized for the negative control.&quot;, shape=&quot;Experiment Type&quot;, colour=&quot;Compound&quot;) + scale_x_continuous(trans = &quot;log10&quot;) # Creating graph To see whether or not there are significant differences, significance tests should be performed. Also a IC50 Curve can be made to visualize the data. "],["open-source-articles.html", "3 Open Source Articles 3.1 Reviewing a closed source article 3.2 Reviewing an open source article", " 3 Open Source Articles Here Ill review a closed source article and an open source article. I will use the Repita Creteria Scores to grade the articles on transparency criteria. Additionaly, A short summary of the articles is given or the code of the research is given and graded on reproducibility 3.1 Reviewing a closed source article The article that has been reviewed is: https://pubmed.ncbi.nlm.nih.gov/32345594/ Dai, M., Liu, D., Liu, M., Zhou, F., Li, G., Chen, Z., Zhang, Z., You, H., Wu, M., Zheng, Q., Xiong, Y., Xiong, H., Wang, C., Chen, C., Xiong, F., Zhang, Y., Peng, Y., Ge, S., Zhen, B., Yu, T.,  Cai, H. (2020). Patients with Cancer Appear More Vulnerable to SARS-CoV-2: A Multicenter Study during the COVID-19 Outbreak. Cancer discovery, 10(6), 783791. https://doi.org/10.1158/2159-8290.CD-20-0422 Table 1: Repita Creteria scores for article by Dai, M. Transparency Criteria Response Study Purpose YES Data Availability Statement YES Data Location https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7309152/bin/candisc-10-783-s001.pdf and https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7309152/bin/candisc-10-783-s002.pdf Study Location YES, 14 hospitals in Hubei province, China Author Review YES, TIER 3 Ethics Statement NO Funding Statement NO Code Availability NO The general aim of this article is a systematic analysis of diverse cohorts of patients with cancer affected by COVID-19. The researchers performed a multicenter study including 105 patients with cancer and 536 age-matched noncancer patients confirmed with COVID-19. The results showed COVID-19 patients with cancer had higher risks in all severe outcomes. The article does not include raw data but only anonymous personal information (risk factors). This includes sex, age, comorbidities, time, tumor type, phase, smoking history, treatments, last time of treatment, servere events and survival status. 3.2 Reviewing an open source article The article that has been reviewed is: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7969711/. With the dataset: https://osf.io/zrx6t/. López Steinmetz LC, Leyes CA, Dutto Florio MA, Fong SB, López Steinmetz RL and Godoy JC (2021) Mental Health Impacts in Argentinean College Students During COVID-19 Quarantine. Front. Psychiatry 12:557880. doi: 10.3389/fpsyt.2021.557880. Table 2: Repita Creteria scores for article by López Steinmetz, L.C. Transparency Criteria Response Study Purpose YES Data Availability Statement YES Data Location https://osf.io/zrx6t/ Study Location YES, Online via LimeSurvey software Author Review YES, TIER 3 Ethics Statement YES Funding Statement NO Code Availability YES The Code I would score the readability of the code with a 5 (Very Easy). Comments are placed at each step and the code is separated in LOAD DATASET/PACKAGES, METHODS, AIM1 and AIM2. It was easy (4) to reproduce the visualization of the project. I only had to change the import of the dataset to read_excel and i had to change the column names with spaces from, for instance, PSYCH.WELLBEING to PSYCH WELLBEING. To see the graphs, change the chunck to eval=TRUE. The code used for this project can be seen here. # R Code for the manuscript entitled: # &quot;Mental health impacts in Argentinean college students during COVID-19 quarantine&quot;. # López Steinmetz L.C., Leyes C.A., Dutto Florio M.A., Fong S.B., López Steinmetz R.L. &amp; Godoy J.C. ########################################################################## ################## LOAD THE DATASET &amp; PACKAGES ########################### ########################################################################## # Load the dataset library(readxl) library(here) table &lt;- read_excel(here(&quot;rawdata/dataset.xlsx&quot;)) summary(table) # Load the packages: library(moments) library(gplots) ########################################################################## ###################### METHODS ########################################### ########################################################################## ###### SUB-TITLE: METHOD &gt; Sample and procedure # SAMPLE N = 2687 # Distribution by sex: table(table$SEX) # Absolute frequencies: Women = 2192, Men = 473, Other = 22 prop.table(table(table$SEX))*100 # Percentages: Women = 81.577968%, Men = 17.603275%, Other = 0.818757% # Central tendency measures by age (total sample) # mean mean(table$AGE) # Mean age = 22.74023 # standard deviation sd(table$AGE) # sd age = 3.635612 # median median(table$AGE) # median age = 22 # Distribution by provinces prop.table(table(table$PROVINCE))*100 # JUJ (JUJUY) = 6.6989207% # SAL (SALTA) = 7.1082992% # CBA (CÓRDOBA) = 39.0026051% # STACR (SANTA CRUZ) = 0.9676219% # TDELF (TIERRA DEL FUEGO) = 2.3446223% # CABA (CIUDAD AUTÓNOMA DE BUENOS AIRES) = 11.9464086% # PCIAB (PROVINCIA DE BUENOS AIRES) = 31.9315221% ###### SUB-TITLE: METHOD &gt; Data analysis ### To test Skewness and Kurtosis # Criteria: range of acceptable values or near to (-3 and +3; Brown, 2006). # Reference: Brown T.A. (2006). Confirmatory factor analysis for applied research. New York: Guilford Press. # PSYCH.WELLBEING skewness(table$`PSYCH WELLBEING`) # skewness PSYCH.WELLBEING = -0.05214941 kurtosis(table$`PSYCH WELLBEING`) # kurtosis PSYCH.WELLBEING = 1.951112 # SOC.FUNC.AND.COPING skewness(table$`SOC FUNC AND COPING`) # skewness SOC.FUNC.AND.COPING = 0.5326852 kurtosis(table$`SOC FUNC AND COPING`) # kurtosis SOC.FUNC.AND.COPING = 2.141538 # K10 skewness(table$K10) # skewness K10 = 0.2819622 kurtosis(table$K10) # kurtosis K10 = 2.248409 # BDI skewness(table$BDI) # skewness BDI = 0.6843361 kurtosis(table$BDI) # kurtosis BDI = 2.907102 # STAIR skewness(table$STAIR) # skewness STAIR = 0.02036605 kurtosis(table$STAIR) # kurtosis STAIR = 2.336078 # YAACQ skewness(table$YAACQ) # skewness YAACQ = 1.21683 kurtosis(table$YAACQ) # kurtosis YAACQ = 4.238449 # ISO30 skewness(table$ISO) # skewness ISO30 = 0.4657512 kurtosis(table$ISO) # kurtosis ISO30 = 2.569562 ### For analyses corresponding to the first aim, we divided the entire sample into four groups: table(table$REGIONS) # NORTH = 371 # CENTER = 1048 # SOUTH = 89 # MOST POPULATED = 1179 ### For analyses corresponding to the second aim, we divided the entire sample into four groups: table(table$`SUB PERIODS IN PRE AND POST`) # first week pre-quarantine extension (ONE WEEK PRE) = 1508 # second week pre-quarantine extension (TWO WEEK PRE) = 525 # first week post-quarantine extension (ONE WEEK POST) = 364 # remaining weeks post-quarantine extension (REMAINING WEEKS POST) = 290 ########################################################################## ###################### RESULTS ########################################### ########################################################################## ########################################################################## ####################### AIM 1 ############################################ ########################################################################## ### Differences in mental health aspects (both general and specific) by four regions # PSYCHOLOGICAL WELL-BEING/DISCOMFORT (OF GENERAL HEALTH) anovaregpsychwellbeing &lt;- aov(table$`PSYCH WELLBEING`~table$REGIONS) summary(anovaregpsychwellbeing) plot(anovaregpsychwellbeing) TukeyHSD(anovaregpsychwellbeing) plot(TukeyHSD(anovaregpsychwellbeing)) # significant differences # MOST POPULATED-CENTER p adj 0.0017158 #### MOST POPULATED mean = 3.206107, CENTER mean = 2.924618 tapply(table$`PSYCH WELLBEING`,factor(table$REGIONS),mean) tapply(table$`PSYCH WELLBEING`,factor(table$REGIONS),sd) # SOCIAL FUNCTIONING AND COPING (OF GENERAL HEALTH) anovaregsocfunc &lt;- aov(table$`SOC FUNC AND COPING`~table$REGIONS) summary(anovaregsocfunc) plot(anovaregsocfunc) TukeyHSD(anovaregsocfunc) plot(TukeyHSD(anovaregsocfunc)) # NO significant differences tapply(table$`SOC FUNC AND COPING`,factor(table$REGIONS),mean) tapply(table$`SOC FUNC AND COPING`,factor(table$REGIONS),sd) # PSYCHOLOGICAL DISTRESS anovaregk10 &lt;- aov(table$K10~table$REGIONS) summary(anovaregk10) plot(anovaregk10) TukeyHSD(anovaregk10) plot(TukeyHSD(anovaregk10)) # NO significant differences tapply(table$K10,factor(table$REGIONS),mean) tapply(table$K10,factor(table$REGIONS),sd) # DEPRESSION anovaregdepr &lt;- aov(table$BDI~table$REGIONS) summary(anovaregdepr) plot(anovaregdepr) TukeyHSD(anovaregdepr) plot(TukeyHSD(anovaregdepr)) # NO significant differences tapply(table$BDI,factor(table$REGIONS),mean) tapply(table$BDI,factor(table$REGIONS),sd) # ANXIETY anovareganx &lt;- aov(table$STAIR~table$REGIONS) summary(anovareganx) plot(anovareganx) TukeyHSD(anovareganx) plot(TukeyHSD(anovareganx)) # NO significant differences tapply(table$STAIR,factor(table$REGIONS),mean) tapply(table$STAIR,factor(table$REGIONS),sd) # NEGATIVE ALCOHOL-RELATED CONSEQUENCES anovaregalc &lt;- aov(table$YAACQ~table$REGIONS) summary(anovaregalc) plot(anovaregalc) TukeyHSD(anovaregalc) plot(TukeyHSD(anovaregalc)) # significant differences # MOST POPULATED-CENTER p adj 0.0001598 ### MOST POPULATED mean = 3.330789, CENTER mean = 4.017176 tapply(table$YAACQ,factor(table$REGIONS),mean) tapply(table$YAACQ,factor(table$REGIONS),sd) # SUICIDAL RISK anovaregsuic &lt;- aov(table$ISO~table$REGIONS) summary(anovaregsuic) plot(anovaregsuic) TukeyHSD(anovaregsuic) plot(TukeyHSD(anovaregsuic)) # NO significant differences tapply(table$ISO,factor(table$REGIONS),mean) tapply(table$ISO,factor(table$REGIONS),sd) ########################################################################## ####################### AIM 2 ############################################ ########################################################################## ### Differences in mental health aspects (both general and specific) by four sub-periods of quarantine # PSYCHOLOGICAL WELL-BEING (OF GENERAL HEALTH) anovatemppsychwellbeing &lt;- aov(table$`PSYCH WELLBEING`~table$`SUB PERIODS IN PRE AND POST`) summary(anovatemppsychwellbeing) plot(anovatemppsychwellbeing) TukeyHSD(anovatemppsychwellbeing) plot(TukeyHSD(anovatemppsychwellbeing)) # significant differences # 4. REMAINING WEEKS POST-1. ONE WEEK PRE p adj 0.0002823 # 3. ONE WEEK POST-2. TWO WEEK PRE p adj 0.0333276 # 4. REMAINING WEEKS POST-2. TWO WEEK PRE p adj 0.0000283 tapply(table$`PSYCH WELLBEING`,factor(table$`SUB PERIODS IN PRE AND POST`),mean) tapply(table$`PSYCH WELLBEING`,factor(table$`SUB PERIODS IN PRE AND POST`),sd) # Figure S1: plotmeans(table$`PSYCH WELLBEING`~table$`SUB PERIODS IN PRE AND POST`, main=&quot;Fig. S1: Psychological well-being/discomfort by quarantine sub-periods. Mean plot with 95% Confidence Interval&quot;, cex.main = 0.8, ylab = &quot;Psychological well-being/discomfort&quot;, xlab = &quot;Quarantine&#39;s sub periods&quot;) # SOCIAL FUNCTIONING AND COPING (OF GENERAL HEALTH) anovatempsocfunc &lt;- aov(table$`SOC FUNC AND COPING`~table$`SUB PERIODS IN PRE AND POST`) summary(anovatempsocfunc) plot(anovatempsocfunc) TukeyHSD(anovatempsocfunc) plot(TukeyHSD(anovatempsocfunc)) # significant differences # 3. ONE WEEK POST-1. ONE WEEK PRE p adj 0.0278280 # 4. REMAINING WEEKS POST-1. ONE WEEK PRE p adj 0.0001652 # 3. ONE WEEK POST-2. TWO WEEK PRE p adj 0.0480422 # 4. REMAINING WEEKS POST-2. TWO WEEK PRE p adj 0.0006543 tapply(table$`SOC FUNC AND COPING`,factor(table$`SUB PERIODS IN PRE AND POST`),mean) tapply(table$`SOC FUNC AND COPING`,factor(table$`SUB PERIODS IN PRE AND POST`),sd) # Figure S2: plotmeans(table$`SOC FUNC AND COPING`~table$`SUB PERIODS IN PRE AND POST`, main=&quot;Fig. S2: Social functioning and coping by quarantine sub-periods. Mean plot with 95% Confidence Interval&quot;, cex.main = 0.8, ylab = &quot;Social functioning and coping&quot;, xlab = &quot;Quarantine&#39;s sub periods&quot;) # PSYCHOLOGICAL DISTRESS anovatempk10 &lt;- aov(table$K10~table$`SUB PERIODS IN PRE AND POST`) summary(anovatempk10) plot(anovatempk10) TukeyHSD(anovatempk10) plot(TukeyHSD(anovatempk10)) # significant differences # 4. REMAINING WEEKS POST-1. ONE WEEK PRE p adj 0.0379214 # 4. REMAINING WEEKS POST-2. TWO WEEK PRE p adj 0.0068317 tapply(table$K10,factor(table$`SUB PERIODS IN PRE AND POST`),mean) tapply(table$K10,factor(table$`SUB PERIODS IN PRE AND POST`),sd) # Figure S3: plotmeans(table$K10~table$`SUB PERIODS IN PRE AND POST`, main=&quot;Fig. S3: Psychological distress by quarantine sub-periods. Mean plot with 95% Confidence Interval&quot;, cex.main = 0.8, ylab = &quot;Psychological distress&quot;, xlab = &quot;Quarantine&#39;s sub periods&quot;) # DEPRESSION anovatempdepr &lt;- aov(table$BDI~table$`SUB PERIODS IN PRE AND POST`) summary(anovatempdepr) plot(anovatempdepr) TukeyHSD(anovatempdepr) plot(TukeyHSD(anovatempdepr)) # NO significant differences tapply(table$BDI,factor(table$`SUB PERIODS IN PRE AND POST`),mean) tapply(table$BDI,factor(table$`SUB PERIODS IN PRE AND POST`),sd) # Figure S4: plotmeans(table$BDI~table$`SUB PERIODS IN PRE AND POST`, main=&quot;Fig. S4: Depression by quarantine sub-periods. Mean plot with 95% Confidence Interval&quot;, cex.main = 0.8, ylab = &quot;Depression&quot;, xlab = &quot;Quarantine&#39;s sub periods&quot;) # ANXIETY anovatempanx &lt;- aov(table$STAIR~table$`SUB PERIODS IN PRE AND POST`) summary(anovatempanx) plot(anovatempanx) TukeyHSD(anovatempanx) plot(TukeyHSD(anovatempanx)) # NO significant differences tapply(table$STAIR,factor(table$`SUB PERIODS IN PRE AND POST`),mean) tapply(table$STAIR,factor(table$`SUB PERIODS IN PRE AND POST`),sd) # Figure S5: plotmeans(table$STAIR~table$`SUB PERIODS IN PRE AND POST`, main=&quot;Fig. S5: Anxiety by quarantine sub-periods. Mean plot with 95% Confidence Interval&quot;, cex.main = 0.8, ylab = &quot;Anxiety&quot;, xlab = &quot;Quarantine&#39;s sub periods&quot;) # NEGATIVE ALCOHOL-RELATED CONSEQUENCES anovatempalc &lt;- aov(table$YAACQ~table$`SUB PERIODS IN PRE AND POST`) summary(anovatempalc) plot(anovatempalc) TukeyHSD(anovatempalc) plot(TukeyHSD(anovatempalc)) # significant differences # 4. REMAINING WEEKS POST-1. ONE WEEK PRE p adj 0.0580130 tapply(table$YAACQ,factor(table$`SUB PERIODS IN PRE AND POST`),mean) tapply(table$YAACQ,factor(table$`SUB PERIODS IN PRE AND POST`),sd) # Figure S6: plotmeans(table$YAACQ~table$`SUB PERIODS IN PRE AND POST`, main=&quot;Fig. S6: Negative alcohol-related consequences by quarantine sub-periods. Mean plot with 95% Confidence Interval&quot;, cex.main = 0.8, ylab = &quot;Negative alcohol-related consequences&quot;, xlab = &quot;Quarantine&#39;s sub periods&quot;) # SUICIDAL RISK anovatempsuic &lt;- aov(table$ISO~table$`SUB PERIODS IN PRE AND POST`) summary(anovatempsuic) plot(anovatempsuic) TukeyHSD(anovatempsuic) plot(TukeyHSD(anovatempsuic)) # NO significant differences tapply(table$ISO,factor(table$`SUB PERIODS IN PRE AND POST`),mean) tapply(table$ISO,factor(table$`SUB PERIODS IN PRE AND POST`),sd) # Figure S7: plotmeans(table$ISO~table$`SUB PERIODS IN PRE AND POST`, main=&quot;Fig. S7: Suicidal risk by quarantine sub-periods. Mean plot with 95% Confidence Interval&quot;, cex.main = 0.8, ylab = &quot;Suicidal risk&quot;, xlab = &quot;Quarantine&#39;s sub periods&quot;) ########################################################################## ############################# THE END #################################### ########################################################################## "],["a-clean-directory.html", "4 A clean directory", " 4 A clean directory A neat working directory is key for an agile workflow and therefore should be applied to all your projects. A technique to clean your working space has been described by the Guerilla Principles. In this part I have cleaned my working directory using the Guerilla Principle 2. My working directory for the DAUR2 course (Institute For Life Sciences and Chemistry (ILC), Hogeschool Utrecht) can be seen here: fs::dir_tree(here::here(&quot;../DAUR2&quot;)) ## C:/Users/sherv/Documents/Hogeschool Utrecht/Life Sciences Jaar 3/Periode C/Minor/Portfolio/../DAUR2 ## +-- code ## | +-- Les1.R ## | +-- Les2.R ## | +-- Les3.R ## | +-- Les4.R ## | +-- Les5.R ## | +-- Les6.R ## | \\-- Les8.R ## +-- data ## | +-- biomaRt_homology_example.rds ## | +-- biomaRt_homology_example_aa.rds ## | +-- biomaRt_homology_example_dna.rds ## | +-- chircus_blg_aminoacids.fasta ## | +-- diet_data.zip ## | +-- GDS858.soft.gz ## | +-- GPL11154.soft ## | +-- GSE116936 ## | | +-- GSE116936_RAW.tar ## | | \\-- GSE116936_series_matrix.txt.gz ## | +-- jp_coldata.txt ## | +-- jp_counts.txt ## | +-- jp_features.txt ## | +-- jp_miame.txt ## | \\-- supp_116936 ## | +-- GSM3264576_A1-Ctrl.txt.gz ## | +-- GSM3264577_A2-Ctrl.txt.gz ## | +-- GSM3264578_A3-Ctrl.txt.gz ## | +-- GSM3264579_B1-PGE2.txt.gz ## | +-- GSM3264580_B2-PGE2.txt.gz ## | +-- GSM3264581_B3-PGE2.txt.gz ## | +-- GSM3264582_I1-TNF.txt.gz ## | +-- GSM3264583_I2-TNF.txt.gz ## | +-- GSM3264584_I3-TNF.txt.gz ## | +-- GSM3264585_J1-TNF+PGE2.txt.gz ## | +-- GSM3264586_J2-TNF+PGE2.txt.gz ## | \\-- GSM3264587_J3-TNF+PGE2.txt.gz ## +-- DAUR2.Rproj ## +-- docs ## | \\-- 20210330_citrul.png ## \\-- Eindopdracht ## +-- daur2_eindopdracht.html ## +-- daur2_eindopdracht.Rmd ## +-- Eindopdracht.Rproj ## \\-- HOXA1.fasta "],["resume.html", "5 Resume", " 5 Resume Shervin Kaandorp Life Science student Personal information Hello! Im Shervin and I am a 21 year old Life Science student. As a young boy i was fascinated by the television series CSI which sparked my interest in labs and DNA. This lead me to choosing a study in which I can immerse myself in these interests. With this education I have broaden my knowledge about cell biology, DNA, Immunology, Hematology and several other areas of the medical biology. I was surprised by my interest in the Research in microbiology area specifically the virology field in which I want to have an internship in. I would like to combine this with my knowledge of data analysis which I learned in the minor Data Sciences for Biology. Education HBO Life Sciences  Hogeschool Utrecht, Utrecht September 2018 - Present Microbiology specialization. Data Sciences for Biology minor 30 EC which covers: Data analysis in Unix and R, a basic introduction in SQL and Python and agile/scrum workflows. Within R I learned to work with Github, Rentrez, Biomart and GEOquery. Also, a project where I analyze the microbiome of water using BLAST in R. VWO  Martinuscollege, Grootebroek September 2012 - July 2018 N&amp;T en N&amp;G package. Working Experience Secretary  V.V.S. Uranymus September 2021 - September 2022 Restaurant worker and attraction operator  Sprookjeswonderland August 2018 - January 2021 Summer job  Soci-Com July 2017  August 2017 Postman  Businesspost Hoorn August 2016  August 2018 Skills Data analysis in R Data analysis in Unix Microsoft Excel Introduction in SQL Introduction in Python Personality Enthousiastic Curious Flexible Reliable Languages Dutch (Native proficiency) English (Full professional proficiency) German (Limited working proficiency) "],["sql-and-r.html", "6 SQL and R", " 6 SQL and R In this part of my portfolio I will import 3 data files into SQL. First, the flu and dengue data files will be downloaded and the gapminder data from dslabs has also been used. download.file(&quot;https://raw.githubusercontent.com/DataScienceILC/tlsc-dsfb26v-20_workflows/main/data/flu_data.csv&quot;, destfile=&quot;data/flu.data.csv&quot;) download.file(&quot;https://raw.githubusercontent.com/DataScienceILC/tlsc-dsfb26v-20_workflows/main/data/dengue_data.csv&quot;, destfile=&quot;data/dengue_data.csv&quot;) flu_data &lt;- read_csv(&quot;data/flu.data.csv&quot;, skip = 10) dengue_data &lt;- read_csv(&quot;data/dengue_data.csv&quot;, skip = 11) gapminder &lt;- dslabs::gapminder After the import, the data has been made tidy. flu_tidy &lt;- flu_data %&gt;% pivot_longer(matches(colnames(flu_data[2:30])), names_to=&quot;country&quot;, values_to =&quot;flu_value&quot;) dengue_tidy &lt;- dengue_data %&gt;% pivot_longer(matches(colnames(dengue_data[2:11])), names_to=&quot;country&quot;, values_to=&quot;dengue_value&quot;) After this the date should be seperated to be the same as the gapminder date and the data should be the same class. # separating date flu_tidy &lt;- separate(flu_tidy, Date, into=c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep=&quot;-&quot;) dengue_tidy &lt;-separate(dengue_tidy, Date, into=c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep=&quot;-&quot;) # assigning numeric class to year and factor to country. flu_tidy$year &lt;- as.numeric(flu_tidy$year) flu_tidy$country &lt;- as.factor(flu_tidy$country) dengue_tidy$year &lt;- as.numeric(dengue_tidy$year) dengue_tidy$country &lt;- as.factor(dengue_tidy$country) # making each year the mean flu_tidy &lt;- flu_tidy %&gt;% group_by(year, country) %&gt;% summarize(&quot;year&quot;=year, &quot;country&quot;=country, &quot;flu_value&quot;=(mean(flu_value, na.rm=TRUE)%&gt;%round(digits=0))) %&gt;% unique() dengue_tidy &lt;- dengue_tidy %&gt;% group_by(year, country) %&gt;% summarize(&quot;year&quot;=year, &quot;country&quot;=country, &quot;dengue_value&quot;=(mean(dengue_value, na.rm=TRUE)%&gt;%round(digits=3))) %&gt;% unique() Now that the data has an uniform format with the same classes and columns, it will be saved as .csv and .rds # writing csv write_csv(dengue_tidy, here::here(&quot;data/dengue_tidy.csv&quot;)) write_csv(flu_tidy, here::here(&quot;data/flu_tidy.csv&quot;)) write_csv(gapminder, here::here(&quot;data/gapminder.csv&quot;)) # writing rds write_rds(dengue_tidy, here::here(&quot;data/dengue_tidy.rds&quot;)) write_rds(flu_tidy, here::here(&quot;data/flu_tidy.rds&quot;)) write_rds(gapminder, here::here(&quot;data/gapminder.rds&quot;)) In DBeaver, a workflowsdb has been made to store this data in. The database is colored blue in the picture. knitr::include_graphics(&quot;doc/workflowsdb.png&quot;) (#fig:picture databases)Figure 1: Databases in DBeaver Now, its time to make a connection with our database inside R! con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host=&quot;localhost&quot;, port=&quot;5432&quot;, user=&quot;postgres&quot;, password=&quot;Shervin.Kaandorp&quot;) Lets write the tables into the database. # overwrite=TRUE has been set to dodge the error when knitting the RMD. dbWriteTable(con, &quot;dengue_tidy&quot;, dengue_tidy, overwrite=TRUE) dbWriteTable(con, &quot;flu_tidy&quot;, flu_tidy, overwrite=TRUE) dbWriteTable(con, &quot;gapminder&quot;, gapminder, overwrite=TRUE) Now Ill inspect wether or not the tables have been written correctly into the database. To see this, I used SELECT * from &lt;table&gt; inside DBeaver. In figure 2 you can see the output for the gapminder table. knitr::include_graphics(&quot;doc/inspectingtables.png&quot;) (#fig:inspecting database)Figure 2: Inspecting the tables in DBeaver Inspecting the tables within R can easily be done with head() command. output has not been shown due to it not being relevant for this markdown. head(dengue_tidy) head(flu_tidy) head(gapminder) Or a connection within R can be made with the database, retrieving the tables with SQL. I will demonstrate this only with the flu_tidy table. SELECT * FROM flu_tidy (#tab:inspecting with sql)Displaying records 1 - 10 year country flu_value 2002 Argentina NA 2002 Australia NA 2002 Austria NA 2002 Belgium NA 2002 Bolivia NA 2002 Brazil 174 2002 Bulgaria NA 2002 Canada NA 2002 Chile NA 2002 France NA Now we will edit the gapminder, flu and dengue table so it can be left joined with the flu and dengue data. sql_gap &lt;- dbReadTable(con, &quot;gapminder&quot;) sql_gap &lt;- sql_gap %&gt;% filter(year==unique(dengue_tidy$year)) dbWriteTable(con, &quot;gapminder_clean&quot;, sql_gap, overwrite=TRUE) I will now left join using SQL and i will write this to another table inside the database. create table gapminder_flu_dengue as select gapminder_clean.*, flu_tidy.flu_value, dengue_tidy.dengue_value from gapminder_clean left join flu_tidy on flu_tidy.country = gapminder_clean.country and flu_tidy.&quot;year&quot; = gapminder_clean.&quot;year&quot; left join dengue_tidy on dengue_tidy.country = gapminder_clean.country and dengue_tidy.&quot;year&quot; = gapminder_clean.&quot;year&quot; Now we are able to import this table from the database to make some beautiful ggplot2 graphs. After this we will not use the database again, therefore we will close the connection. gapminder_flu_dengue &lt;- dbReadTable(con, &quot;gapminder_flu_dengue&quot;) dbDisconnect(con) gapminder_flu_dengue %&gt;% filter(flu_value&gt;0) %&gt;% ggplot(aes(x=year, y=flu_value)) + geom_line(aes(colour=country)) + geom_point(aes(colour=country)) + labs(title=&quot;Average flu values for countries between 2002 and 2015&quot;, x=&quot;Year&quot;, y=&quot;flu value&quot;, caption=&quot;Figure 3: data from gapminder, flu and dengue dataset. The points in the graph are the only values which both has a year and a flu value. For the countries with multiple data points, we can see a negative trend.&quot;) gapminder_flu_dengue %&gt;% filter(dengue_value&gt;0) %&gt;% ggplot(aes(x=year, y=dengue_value)) + geom_line(aes(colour=country)) + geom_point(aes(colour=country)) + labs(title=&quot;Average dengue values for countries between 2002 and 2015&quot;, x=&quot;Year&quot;, y=&quot;Dengue value&quot;, caption=&quot;Figure 4: data from gapminder, flu and dengue dataset. The points in the graph are the only values which both has a year and a dangue value.&quot;) gapminder_flu_dengue %&gt;% filter(flu_value&gt;0 &amp; dengue_value&gt;0) %&gt;% ggplot(aes(x=dengue_value, y=flu_value)) + geom_line(aes(colour=country)) + geom_point(aes(colour=country)) + labs(title=&quot;Flu value to dengue value for countries between 2002 and 2015&quot;, x=&quot;Dengue value&quot;, y=&quot;Flue value&quot;, caption=&quot;Figure 5: data from gapminder, flu and dengue dataset. The points in the graph are the only values which both has a dengue value and a flu value. Bolivia has a high flu value and a low dengue value while Brazil has a low flu value and a high dengue value.&quot;) "],["making-a-package.html", "7 Making a package", " 7 Making a package The link to my package can be found here "],["parameters-in-r-markdown.html", "8 Parameters in R Markdown", " 8 Parameters in R Markdown In this part of my portfolio, I will use parameters to show some graphs using COVID-19 data from the EDCC. First, ofcourse, we have to read the file cases_deaths &lt;- read_csv(here::here(&quot;data/edcc_data.csv&quot;)) Now we will filter the data on the year, date and country parameter. filtered_data &lt;- cases_deaths %&gt;% filter(countriesAndTerritories == params$country, year == params$year, month == params$month) Now that the data is filtered, we have to make dates for our x-axis in the graph. filtered_data$date &lt;- paste(filtered_data$day, filtered_data$month, filtered_data$year, sep=&quot;-&quot;) filtered_data$date &lt;- as.Date(filtered_data$date, &quot;%d-%m-%y&quot;) filtered_data %&gt;% filter(day &gt; 1) %&gt;% ggplot(aes(x=date, y=cases)) + geom_line() + geom_point() + theme(axis.text.x = element_text(angle = 90)) + labs(x=&quot;Date&quot;, y=&quot;Cases&quot;, title=paste(&quot;COVID-19 cases in the&quot;, params$country, &quot;between&quot;, filtered_data$date[length(filtered_data$date)], &quot;and&quot;, filtered_data$date[1] ), caption=&quot;Figure 1: Data from EDCC, data on the daily number of new reported COVID-19 cases and deaths by EU/EEA country&quot;) filtered_data %&gt;% filter(day &gt; 1) %&gt;% ggplot(aes(x=date, y=deaths)) + geom_line() + geom_point() + theme(axis.text.x = element_text(angle = 90)) + labs(x=&quot;Date&quot;, y=&quot;Deaths&quot;, title=paste(&quot;COVID-19 deaths in the&quot;, params$country, &quot;between&quot;, filtered_data$date[length(filtered_data$date)], &quot;and&quot;, filtered_data$date[1] ), caption=&quot;Figure 2: Data from EDCC, data on the daily number of new reported COVID-19 cases and deaths by EU/EEA country&quot;) "],["introduction-in-python.html", "9 Introduction in Python 9.1 Part 1: Programming 9.2 Part 2: Using Biopython 9.3 Part 3: Advanced Topics 9.4 Part 4: Python Recipes", " 9 Introduction in Python For my self study I started learning Python. Python is very interesting to me because it is the most used programming language in the world. I want to learn multiple coding languages to broaden myself. To learn Python I am using the book Python for Bioinformatics by Sebastian Bassi which learns me to use Python in shell and how to adapt bioinformatics in python. In this markdown Ill describe what I have learned from this guide. 9.1 Part 1: Programming To start my Python journey I obviously have to know how strings, calculation and other basic principles work. I started printing Hello World to the screen using print(\"Hello World\") (see the figure) Ive also seen the first big difference between R and Python. In Python, you can add strings together doing 'Hello' + 'World' or '1'+'1' as seen below (the strings cannot be added together when the classes are not the same). This is not possible with R, this gives the error: Error in \"1\" + \"1\" : non-numeric argument to binary operator. In R one should use paste('Hello','World'). (#fig:hello world!)Figure 1: hello world! The next thing I noticed was the use of functions. In Python you can add strings to a function easily by doing &lt;string&gt;.&lt;function&gt;(). In the example I made a DNA strand called dna and I used the replace function to replace each a with an h (which isnt relevant but it shows how it works). Figure 9.1: Figure 2: replacing and input the dna Also, numbers are different in Python. In R, if we say &lt;string&gt;[1] we get the first value in this string. But in python this is the second. Also when we say &lt;string&gt;[1:2] we get the first and second value in the string in R. In python we only get the second. I will showcase some self evaluation assignments, which are inside the guide. First i will make a program that checks whether or not a number is a palindrome. Now i will make a program that asks for your name and writes it to MyName.txt. 9.2 Part 2: Using Biopython 9.3 Part 3: Advanced Topics 9.4 Part 4: Python Recipes "],["analyzing-a-water-microbiome.html", "10 Analyzing a water microbiome", " 10 Analyzing a water microbiome In the DSFB minor i got assigned to analyze a water microbiome. In this part of my portfolio I will give a short description about this project. I did not add this to my portfolio because of time. "],["in-the-future.html", "11 In the future", " 11 In the future In 2 years i will be at the end of my study. I have done my internship (preferably in virology), and will orient myself into what jobs are available. My passion is with virology and it would be fantastic to implement bioinformatics into my job. Still I dont wat to be behind a computer for 90 percent of the time but I want a job where lab work and bioinformatics are distributed equally. Before I will graduate I want to broaden myself into the world of Bioinformatics. I have done this in the workflows course of the Data Sciences for Biology minor by deepen myself into Python. After this course i want to continue working with R in my projects and my internship. "]]
